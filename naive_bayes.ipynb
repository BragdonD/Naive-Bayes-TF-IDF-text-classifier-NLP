{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_dataset(path):\n",
    "    \"\"\"Function to load a dataset from a csv file\n",
    "\n",
    "    Args:\n",
    "        path (str): relative path to the csv file\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: the dataframe load\n",
    "    \"\"\"\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_csv_dataset(\"train_40k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>Title</th>\n",
       "      <th>userId</th>\n",
       "      <th>Helpfulness</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cat1</th>\n",
       "      <th>Cat2</th>\n",
       "      <th>Cat3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000E46LYG</td>\n",
       "      <td>Golden Valley Natural Buffalo Jerky</td>\n",
       "      <td>A3MQDNGHDJU4MK</td>\n",
       "      <td>0/0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>The description and photo on this product need...</td>\n",
       "      <td>grocery gourmet food</td>\n",
       "      <td>meat poultry</td>\n",
       "      <td>jerky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000GRA6N8</td>\n",
       "      <td>Westing Game</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>860630400</td>\n",
       "      <td>This was a great book!!!! It is well thought t...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>games</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000GRA6N8</td>\n",
       "      <td>Westing Game</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>883008000</td>\n",
       "      <td>I am a first year teacher, teaching 5th grade....</td>\n",
       "      <td>toys games</td>\n",
       "      <td>games</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000GRA6N8</td>\n",
       "      <td>Westing Game</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>897696000</td>\n",
       "      <td>I got the book at my bookfair at school lookin...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>games</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00000DMDQ</td>\n",
       "      <td>I SPY A is For Jigsaw Puzzle 63pc</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2/4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>911865600</td>\n",
       "      <td>Hi! I'm Martine Redman and I created this puzz...</td>\n",
       "      <td>toys games</td>\n",
       "      <td>puzzles</td>\n",
       "      <td>jigsaw puzzles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    productId                                Title          userId  \\\n",
       "0  B000E46LYG  Golden Valley Natural Buffalo Jerky  A3MQDNGHDJU4MK   \n",
       "1  B000GRA6N8                         Westing Game         unknown   \n",
       "2  B000GRA6N8                         Westing Game         unknown   \n",
       "3  B000GRA6N8                         Westing Game         unknown   \n",
       "4  B00000DMDQ    I SPY A is For Jigsaw Puzzle 63pc         unknown   \n",
       "\n",
       "  Helpfulness  Score       Time  \\\n",
       "0         0/0    3.0         -1   \n",
       "1         0/0    5.0  860630400   \n",
       "2         0/0    5.0  883008000   \n",
       "3         0/0    5.0  897696000   \n",
       "4         2/4    5.0  911865600   \n",
       "\n",
       "                                                Text                  Cat1  \\\n",
       "0  The description and photo on this product need...  grocery gourmet food   \n",
       "1  This was a great book!!!! It is well thought t...            toys games   \n",
       "2  I am a first year teacher, teaching 5th grade....            toys games   \n",
       "3  I got the book at my bookfair at school lookin...            toys games   \n",
       "4  Hi! I'm Martine Redman and I created this puzz...            toys games   \n",
       "\n",
       "           Cat2            Cat3  \n",
       "0  meat poultry           jerky  \n",
       "1         games         unknown  \n",
       "2         games         unknown  \n",
       "3         games         unknown  \n",
       "4       puzzles  jigsaw puzzles  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"productId\", axis=1)\n",
    "df = df.drop(\"Title\", axis=1)\n",
    "df = df.drop(\"userId\", axis=1)\n",
    "df = df.drop(\"Helpfulness\", axis=1)\n",
    "df = df.drop(\"Score\", axis=1)\n",
    "df = df.drop(\"Time\", axis=1)\n",
    "df = df.drop(\"Cat2\", axis=1)\n",
    "df = df.drop(\"Cat3\", axis=1)\n",
    "df = df.rename(columns={\"Text\": \"description\", \"Cat1\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The description and photo on this product need...</td>\n",
       "      <td>grocery gourmet food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This was a great book!!!! It is well thought t...</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a first year teacher, teaching 5th grade....</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got the book at my bookfair at school lookin...</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! I'm Martine Redman and I created this puzz...</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description                 label\n",
       "0  The description and photo on this product need...  grocery gourmet food\n",
       "1  This was a great book!!!! It is well thought t...            toys games\n",
       "2  I am a first year teacher, teaching 5th grade....            toys games\n",
       "3  I got the book at my bookfair at school lookin...            toys games\n",
       "4  Hi! I'm Martine Redman and I created this puzz...            toys games"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "remove_symbols = re.compile('[-+/(){}\\[\\]\\|@,;]')\n",
    "remove_numbers = re.compile('[0-9] {,1}')\n",
    "PUNCTUATION = string.punctuation\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence):\n",
    "    \"\"\"Function to lemmatize a sentence\n",
    "\n",
    "    Args:\n",
    "        sentence (str): the string to lemmatize\n",
    "\n",
    "    Returns:\n",
    "        str: the lemmatized string\n",
    "    \"\"\"\n",
    "    doc = lemmatizer(sentence)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "def text_preprocess(sentence):\n",
    "    \"\"\"Function to preprocess a sentence to remove punctuation, emoji, symbols and to lemmatize\n",
    "\n",
    "    Args:\n",
    "        sentence (str): sentence to be preprocess\n",
    "\n",
    "    Returns:\n",
    "        str: the new sentence\n",
    "    \"\"\"\n",
    "    if isinstance(sentence, str):\n",
    "        sentence = sentence.lower() ## Make the text lower case\n",
    "        sentence = sentence.translate(str.maketrans('', '', PUNCTUATION)) ## Remove the punctuation\n",
    "        sentence = emoji_pattern.sub(' ', sentence)\n",
    "        sentence = remove_symbols.sub(' ', sentence)\n",
    "        sentence = remove_numbers.sub(' ', sentence)\n",
    "        sentence = lemmatize_sentence(sentence)\n",
    "        return sentence\n",
    "    Exception(\"sentence need to be a string.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [04:18<00:00, 154.63it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas() ## To display a progress bar\n",
    "df.description = df.description.progress_apply(lambda text : text_preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, stratify=df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    return [word for word in sentence.split(\" \") if word != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \"\"\"Naive Bayes classe to implement naive bayes algorithm with nGram\n",
    "    \"\"\"\n",
    "    def __init__(self, classes):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            classes (np.array): classes of the dataset\n",
    "        \"\"\"\n",
    "        self.classes = np.unique(classes)\n",
    "        self.nb_classes = len(classes)\n",
    "        self.istrain = False\n",
    "    \n",
    "    def get_classes_occ(self, Y):\n",
    "        self.classes_occ = dict()\n",
    "        for y in Y:\n",
    "            if y not in self.classes_occ:\n",
    "                self.classes_occ[y] = 0\n",
    "            self.classes_occ[y] += 1\n",
    "    \n",
    "    def get_word_occ(self, X, Y):\n",
    "        self.word_occ_classes = dict()\n",
    "        for cl in self.classes:\n",
    "            self.word_occ_classes[cl] = dict()\n",
    "        for x, y in tqdm(zip(X,Y), total=len(X)):\n",
    "            for word in tokenize(x):\n",
    "                if word not in self.word_occ_classes[y]:\n",
    "                    self.word_occ_classes[y][word] = 0\n",
    "                self.word_occ_classes[y][word] += 1\n",
    "                \n",
    "    def get_tf(self, word, label, len):\n",
    "        N = len\n",
    "        occ = self.word_classes_occ[label][word]\n",
    "        return occ/N\n",
    "\n",
    "    def get_idf(self, word):\n",
    "        try:\n",
    "            occ = self.words_occ[word] + 1\n",
    "        except:\n",
    "            occ = 1\n",
    "        return np.log(float(len(self.X)) / float(self.word_occ[word]))\n",
    "    \n",
    "    def get_tf_idf(self, corpus, label):\n",
    "        \n",
    "        def get_class_words(label):\n",
    "            words = 0\n",
    "            for key, val in self.word_classes_occ[label].items():\n",
    "                words += val\n",
    "            return words\n",
    "        \n",
    "        def get_word_occ_data(word):\n",
    "            words = 0\n",
    "            for key, val in self.word_classes_occ.items():\n",
    "                if word in val:\n",
    "                    words += val[word]\n",
    "            return words\n",
    "        \n",
    "        vec = np.zeros((len(self.vocab),))\n",
    "        tokens = tokenize(corpus)\n",
    "        tokens_len = len(tokens)\n",
    "        print(f\"tf idf of corpus {label}\")\n",
    "        for word in tqdm(np.unique(tokens)):\n",
    "            tf = self.word_classes_occ[label][word] / get_class_words(label)\n",
    "            idf = np.log(len(self.X) / get_word_occ_data(word))\n",
    "            vec[self.word_index[word]] = tf * idf\n",
    "        return vec\n",
    "    \n",
    "    def get_classes_proba(self, Y, classes_occ):\n",
    "        self.classes_proba = dict()\n",
    "        for cl, val in classes_occ.items():\n",
    "            self.classes_proba[cl] = np.log(float(val) / float(len(Y)))\n",
    "        \n",
    "    def create_corpus(self, X, Y):\n",
    "        self.corpus = dict()\n",
    "        for x, y in zip(X, Y):\n",
    "            if y not in self.corpus:\n",
    "                self.corpus[y] = []\n",
    "            self.corpus[y].append(x)\n",
    "        for cl, arr in self.corpus.items():\n",
    "            self.corpus[cl] = \" \".join(self.corpus[cl])\n",
    "            \n",
    "    def train(self, X, Y):\n",
    "        \"\"\"Function to create the tf-idf for naive bayes algo\n",
    "\n",
    "        Args:\n",
    "            X (np.array): the text to process\n",
    "            Y (np.array): the label for each text\n",
    "        \"\"\"\n",
    "        if len(X) != len(Y):\n",
    "            Exception(\"X and Y need to have the same length.\")\n",
    "        self.X = X #Store the dataset\n",
    "        self.Y = Y #Store the dataset\n",
    "        self.create_corpus(self.X, self.Y)\n",
    "        self.get_classes_occ(self.Y)\n",
    "        self.get_classes_proba(self.Y, self.classes_occ)\n",
    "        \n",
    "        self.vocab = dict()\n",
    "        self.word_index = dict()\n",
    "        self.word_occ = dict()\n",
    "        self.word_classes_occ = dict()\n",
    "        index = 0\n",
    "        for label in self.classes:\n",
    "            self.word_classes_occ[label] = dict()\n",
    "        for sentence, label in tqdm(zip(self.X, self.Y), total=len(self.X)): ### Calculate vocab size\n",
    "            for word in tokenize(sentence):\n",
    "                if word not in self.vocab: ## Update the vocab\n",
    "                    self.word_occ[word] = 0\n",
    "                    self.vocab[word] = 1\n",
    "                    self.word_index[word] = index\n",
    "                    index += 1 \n",
    "                if word not in self.word_classes_occ[label]:\n",
    "                    self.word_classes_occ[label][word] = 0\n",
    "                    \n",
    "                self.word_classes_occ[label][word] += 1\n",
    "                self.word_occ[word] += 1                   \n",
    "\n",
    "        self.word_tf_idf_classes = dict()\n",
    "        self.classes_tf_idf_total = dict()\n",
    "        for y in self.classes:\n",
    "            self.word_tf_idf_classes[y] = dict()\n",
    "            self.classes_tf_idf_total[y] = 0\n",
    "            vector = self.get_tf_idf(self.corpus[y],y)\n",
    "            for i, value in tqdm(enumerate(vector), total=len(vector)):\n",
    "                self.classes_tf_idf_total[y] += value\n",
    "                self.word_tf_idf_classes[y][i] = value\n",
    "                \n",
    "        self.denominators = np.zeros((len(self.classes),))\n",
    "        for i, cl in enumerate(self.classes):\n",
    "            self.denominators[i] = self.classes_tf_idf_total[cl] + len(self.vocab)\n",
    "        self.istrain = True         \n",
    "    \n",
    "    def predict(self, text):\n",
    "        \"\"\"Function to get the probabilities of each classes for a given sentence\n",
    "\n",
    "        Args:\n",
    "            text (str): a preprocess sentence to evaluate the classe\n",
    "        \n",
    "        Return:\n",
    "            (np.array): an array containing the proba of each classes for the given sentence.\n",
    "            The proba are given in log space.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.istrain != True:\n",
    "            Exception(\"Model is not train\")\n",
    "        likelihood_prob = np.zeros(self.classes.shape[0]) ## Initialize proba at 0 for each class\n",
    "        for i, y in enumerate(self.classes):\n",
    "            for token in tokenize(text):\n",
    "                \"\"\"Calculate the proba for each token in the sentence.\n",
    "                The token need to be in the vocab else it is ignore\n",
    "                \"\"\"\n",
    "                if token in self.vocab: ### We ignore the word if not in the vocab\n",
    "                    token_index = self.word_index[token]\n",
    "                    token_tf_idf = 0\n",
    "                    if token_index in self.word_tf_idf_classes[y]:\n",
    "                        token_tf_idf = self.word_tf_idf_classes[y][token_index]\n",
    "                    token_tf_idf += 1 ### Laplace\n",
    "                    token_prob = float(token_tf_idf)/float(self.denominators[i]) ### Final proba of the token\n",
    "                    likelihood_prob[i] += token_prob ### Calculating somme of proba of each token\n",
    "        return likelihood_prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:01<00:00, 16039.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf idf of corpus baby products\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12566/12566 [00:09<00:00, 1265.20it/s]\n",
      "100%|██████████| 55537/55537 [00:00<00:00, 1790048.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf idf of corpus beauty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13446/13446 [00:11<00:00, 1218.93it/s]\n",
      "100%|██████████| 55537/55537 [00:00<00:00, 1633536.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf idf of corpus grocery gourmet food\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10411/10411 [00:06<00:00, 1662.30it/s]\n",
      "100%|██████████| 55537/55537 [00:00<00:00, 1851735.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf idf of corpus health personal care\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21579/21579 [00:32<00:00, 658.06it/s]\n",
      "100%|██████████| 55537/55537 [00:00<00:00, 1981330.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf idf of corpus pet supplies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12861/12861 [00:09<00:00, 1379.52it/s]\n",
      "100%|██████████| 55537/55537 [00:00<00:00, 1635107.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf idf of corpus toys games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21869/21869 [00:30<00:00, 713.25it/s]\n",
      "100%|██████████| 55537/55537 [00:00<00:00, 1852147.71it/s]\n"
     ]
    }
   ],
   "source": [
    "nb.train(train.description.values, train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test):\n",
    "    \"\"\"Function to test our model performance\n",
    "\n",
    "    Args:\n",
    "        model (NaiveBayes): a Naive Bayes model\n",
    "        test (pd.Dataframe): the test dataframe\n",
    "\n",
    "    Returns:\n",
    "        int: the accuracy of the model\n",
    "    \"\"\"\n",
    "    success = 0\n",
    "    for x_test, y_test in tqdm(zip(test.description.values, test.label.values), total=len(test.label)):\n",
    "        if model.classes[model.predict(x_test).argmax()] == y_test:\n",
    "            success += 1\n",
    "    return (float(success) / len(test.label.values)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:04<00:00, 1992.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34.5875"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(nb, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f56dc8f305b8407d8b48cc33503d84dbeabbbd03fe8c646d69c42e169c35af6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
